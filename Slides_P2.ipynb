{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Programming Series\n",
    "\n",
    "### Part 2: Applications using the Fundamentals\n",
    "\n",
    "\n",
    "<img src=\"arcpy.jpg\" width=\"400\" height=\"400\">\n",
    "\n",
    "#### Topics\n",
    "\n",
    "1.  A quick talk about Packages\n",
    "\n",
    "2.\tExamples of how to use conditionals and loops to iterate multiple processes over large datasets\n",
    "\n",
    "3.\tDiscussion on how and when to use different data structures.\n",
    "\n",
    "4.\tIntegrating Arcpy snippets into loops for automating geo-processing tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n",
    "\n",
    "\n",
    "#### Tell python you want acess to a Package \n",
    "(or stated in different terms, load in a library of functions):\n",
    "\n",
    "    import package\n",
    "\n",
    "#### Access the functions in that library:\n",
    "\n",
    "    package.function(x)\n",
    "\n",
    "\n",
    "<img src=\"anaconda.png\" width=\"100\" height=\"100\">\n",
    "\n",
    "Anaconda Default Package List:\n",
    "https://docs.continuum.io/anaconda/pkg-docs\n",
    "\n",
    "PyPI Ranking:\n",
    "http://pypi-ranking.info/alltime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#--- Example: Numeric Python or numpy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#sin3 = np.sin(3)\n",
    "#print sin3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# NYSERDA Infrastructure Vulnerability Project:\n",
    "\n",
    "### Goal: Identify bridges vulnerable to failure from debris accumulation during flood events\n",
    "\n",
    "#### Example Dataset & Task:\n",
    "\n",
    "    Point File (12,000 Bridges): \n",
    "    \n",
    "        1. Get Current Flows for 10 return periods, at each point\n",
    "        \n",
    "        2. Get Future Flows for 10 return periods for 30 Different Precipitation Scenarios, at each point\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Current Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"SIR2006_5112.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydrologic Regions of New York\n",
    "\n",
    "<img src=\"HydroRegions.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute each shapefile with field with Hydrologic Group:\n",
    "    Intersect Each Subbasin File with the Hydro-Regions File\n",
    "\n",
    "#### Packages needed: os, glob, arcpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#help(os)\n",
    "#help(glob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.python.org/2/library/os.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#---Import modules\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "#---Assign Directory of saved Streamstats files \n",
    "SS_dir = \"P:\\Temp\\NEWYORK\\ARCHIVE\"\n",
    "\n",
    "#---Assign Path of Hydro Regions\n",
    "hydro_regions = \"W:\\CCSI\\TECH\\NYSERDA\\InfrastructureVulnerability\\Task6\\SnappedBridges\\ExpandedHydrRegions.shp\"\n",
    "\n",
    "#---Get a list of all Streamstats Geodatabases \n",
    "gdbs = glob(os.path.join(SS_dir,'*.gdb'))\n",
    "\n",
    "for gdb in gdbs:\n",
    "    print gdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have:\n",
    "    1. A path list of all of the geodadabases containint the shapefiles to be intersected\n",
    "    2. The Hydro-regions shapefile to intersect them with.\n",
    "    \n",
    "### We need a name for the output files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for gdb in gdbs:\n",
    "    print gdb.split('\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for gdb in gdbs:\n",
    "    print gdb.split('\\\\')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for gdb in gdbs:\n",
    "    print gdb.split('\\\\')[-1].split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for gdb in gdbs:\n",
    "    print gdb.split('\\\\')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for gdb in gdbs:\n",
    "    print gdb.split('\\\\')[-1].split('.')[0].split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for gdb in gdbs:\n",
    "    print gdb.split('\\\\')[-1].split('.')[0].split('_')[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#--Lets choose what we want and assign it to a variable \n",
    "for gdb in gdbs:\n",
    "    print gdb.split('\\\\')[-1].split('.')[0].split('_')[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have:\n",
    "    1. A path list of all of the geodadabases containint the shapefiles to be intersected\n",
    "    2. The Hydro-regions shapefile to intersect them with.\n",
    "    3. A new name for each ouput file\n",
    "    \n",
    "### Now we can add the inputs into an arcpy function    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for gdb in gdbs:\n",
    "    newfile = 'intersect_' + gdb.split('\\\\')[-1].split('.')[0].split('_')[1:3][1]\n",
    "    print newfile\n",
    "    \n",
    "    #----What happened to READABILITY COUNTS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import arcpy\n",
    "watershed = 'GlobalWatershed'\n",
    "\n",
    "for gdb in gdbs:\n",
    "    \n",
    "    newfile = 'intersect_' + gdb.split('\\\\')[-1].split('.')[0].split('_')[1:3][1]\n",
    "    \n",
    "    try:\n",
    "        #arcpy.env.workspace = gdb                #---Set the workspace \n",
    "       \n",
    "        inFeatures = [watershed,hydro_regions]    #---Assign Inputs\n",
    "        intersectOutput =  \"%s\" %(newfile)        #---Assign Ouputs\n",
    "        \n",
    "        #print \"Geodatabase = \", gdb\n",
    "        #print \"Inputs= \", inFeatures\n",
    "        #print \"NewFile = \", intersectOutput\n",
    "        #arcpy.Intersect_analysis(inFeatures, intersectOutput, polygon\")\n",
    "    \n",
    "    except:\n",
    "        print\"Houston we have a problem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We now have a new file, attributed with hydrologic Region data:\n",
    "\n",
    "### We can calculate Regression Flows\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydrologic Regions of New York\n",
    "\n",
    "<img src=\"pop_rec_fields.png\" width=\"1000\" height=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we need?\n",
    "\n",
    "    1. A list of coefficients for each return period\n",
    "    2. A list of exponents for each factor, in each return period\n",
    "    3. The factors for each subbasin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---Recurrence Intervals & Hydrologic Regions\n",
    "recurrence   = ['Q1_25','Q1_5','Q2','Q5','Q10','Q25',\n",
    "                'Q50','Q100','Q200','Q500']\n",
    "\n",
    "#print recurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recurrence   = ['Q1_25','Q1_5','Q2','Q5','Q10','Q25',\n",
    "                'Q50','Q100','Q200','Q500']\n",
    "\n",
    "for r in recurrence:\n",
    "    print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#---Hydrologic Regions\n",
    "region       = ['R1','R2','R3','R4','R5','R6']\n",
    "\n",
    "#print region\n",
    "for r in region:\n",
    "    print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#---Coefficient Dictionaries by Hydrologic Regions\n",
    "c1 = {\"Q1_25\":69.0,\"Q1_5\":144.0, \"Q2\":299.0,\"Q5\":1180.0,\"Q10\":2310.0,\n",
    "      \"Q25\":4580.0,\"Q50\":7030.0,\"Q100\":10300.0,\"Q200\":14500.0,\n",
    "      \"Q500\":22000.0}\n",
    "\n",
    "#print c1\n",
    "for key in c1:\n",
    "    print key #, c1[key] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Regression Equations for each Return Period\n",
    "R1Q1_25 = {'A': 0.972,'ST':-0.160, 'P':1.859,'LAG':-0.355,'FOR':-1.514}\n",
    "R1Q1_5  = {'A': 0.973,'ST':-0.164, 'P':1.718,'LAG':-0.383,'FOR':-1.519}\n",
    "R1Q2    = {'A': 0.972,'ST':-0.169, 'P':1.576,'LAG':-0.411,'FOR':-1.518}\n",
    "R1Q5    = {'A': 0.970,'ST':-0.178, 'P':1.335,'LAG':-0.460,'FOR':-1.530}\n",
    "R1Q10   = {'A': 0.968,'ST':-0.184, 'P':1.241,'LAG':-0.482,'FOR':-1.549}\n",
    "R1Q25   = {'A': 0.965,'ST':-0.192, 'P':1.167,'LAG':-0.500,'FOR':-1.582}\n",
    "R1Q50   = {'A': 0.963,'ST':-0.197, 'P':1.131,'LAG':-0.511,'FOR':-1.610}\n",
    "R1Q100  = {'A': 0.962,'ST':-0.202, 'P':1.106,'LAG':-0.520,'FOR':-1.638}\n",
    "R1Q200  = {'A': 0.960,'ST':-0.206, 'P':1.086,'LAG':-0.528,'FOR':-1.667}\n",
    "R1Q500  = {'A': 0.959,'ST':-0.210, 'P':1.067,'LAG':-0.539,'FOR':-1.704}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#List of Regression Equations for each Return Period\n",
    "e1 = [R1Q1_25,R1Q1_5,R1Q2,R1Q5,R1Q10,R1Q25,R1Q50,R1Q100,R1Q200,R1Q500]\n",
    "\n",
    "#print e1\n",
    "print e1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, recur in enumerate(recurrence):\n",
    "    print i, recur\n",
    "    \n",
    "# i = position in the list called: recurrence\n",
    "# recur = the object in position i of recurrence  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1= {'c':c1,'e':e1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r1_qs(A,ST,P,LAG,FOR,p):\n",
    "    OUTPUT = []\n",
    "    for i, recur in enumerate(recurrence):\n",
    "        coeff = p['c'][recur]\n",
    "        e1 = p['e'][i]['A']     \n",
    "        e2 = p['e'][i]['ST'] \n",
    "        e3 = p['e'][i]['P'] \n",
    "        e4 = p['e'][i]['LAG']  \n",
    "        e5 = p['e'][i]['FOR']  \n",
    "        Q = coeff*(A)**e1*(ST+1)**e2*(P)**e3*(LAG+1)**e4*(FOR+80)**e5\n",
    "        OUTPUT.append(Q)\n",
    "    return OUTPUT  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "area = 20\n",
    "storage = 0.36\n",
    "precip = 42\n",
    "lag = 1\n",
    "forest = 0.96\n",
    "\n",
    "flows = r1_qs(area,storage,precip,lag,forest,p1)\n",
    "#print flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flows = r1_qs(area,storage,precip,lag,forest,p1)\n",
    "\n",
    "#for flow in flows:\n",
    "#    print flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flows = r1_qs(area,storage,precip,lag,forest,p1)\n",
    "\n",
    "#for i,flow in enumerate(flows):\n",
    "    #print i,flow\n",
    "#    print recurrence[i],flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flows = r1_qs(area,storage,precip,lag,forest,p1)\n",
    "for i,flow in enumerate(flows):\n",
    "    #print i,flow\n",
    "    print recurrence[i], '\\t', round(flow,0), 'cfs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are done with Part 1: \n",
    "\n",
    "### Just write a loop to go through all of the subbasins read the attributes, calculate the flows & write to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Calculate Future flows, NY Tool\n",
    "\n",
    "<img src=\"tool_1.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Subbasin for each bridge\n",
    "\n",
    "<img src=\"tool_2.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Subbasin for each bridge\n",
    "\n",
    "<img src=\"tool_map.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Subbasin for each bridge\n",
    "\n",
    "<img src=\"tool_3.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Subbasin for each bridge\n",
    "\n",
    "<img src=\"tool_4.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Subbasin for each bridge\n",
    "\n",
    "<img src=\"tool_5.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What has changed? ==> Precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "intersect shapefiles in Master_Batch_13_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "1\n",
      "intersect shapefiles in Master_Batch_06_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "2\n",
      "intersect shapefiles in Master_Batch_03_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "3\n",
      "intersect shapefiles in Master_Batch_02_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "4\n",
      "intersect shapefiles in Master_Batch_C1_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "5\n",
      "intersect shapefiles in Master_Batch_11_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "6\n",
      "intersect shapefiles in Master_Batch_01_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "7\n",
      "intersect shapefiles in Master_Batch_08_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "8\n",
      "intersect shapefiles in Master_Batch_10_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "9\n",
      "intersect shapefiles in Master_Batch_09_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "10\n",
      "intersect shapefiles in Master_Batch_04_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "11\n",
      "intersect shapefiles in Master_Batch_07_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "12\n",
      "intersect shapefiles in Master_Batch_12_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "13\n",
      "intersect shapefiles in Master_Batch_05_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "14\n",
      "intersect shapefiles in Master_Batch_C2_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n",
      "15\n",
      "intersect shapefiles in Master_Batch_DoubleCheck_QC.gdb with precip grids\n",
      "\tGroup the output by ensemble: Forecast Period & Climate Scenario\n",
      "\t\tGet mean, max, min, standard deviation for each ensemble and write to file\n",
      "\t\t\tManually check points against the values computed in the NY Tool and pray they are the same\n"
     ]
    }
   ],
   "source": [
    "#Work out the logic\n",
    "\n",
    "#Copy and paste\n",
    "\n",
    "for i, gdb in enumerate(gdbs):\n",
    "    print i\n",
    "    job1 = 'intersect shapefiles in %s with precip grids' % (gdb.split('\\\\')[-1])\n",
    "    print job1\n",
    "    \n",
    "    job2 = 'Group the output by ensemble: Forecast Period & Climate Scenario'\n",
    "    print '\\t' + job2\n",
    "    \n",
    "    job3 = 'Get mean, max, min, standard deviation for each ensemble and write to file'\n",
    "    print '\\t\\t' + job3\n",
    "    \n",
    "    job4 = 'Manually check points against the values computed in the NY Tool and pray they are the same'\n",
    "    print '\\t\\t\\t' + job4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jared Dorvinen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
